{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "winobias_attention_experiments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrcRikY3MCoJUk4X/1CgVb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fabc56aa28f74782b2663569cbe6c603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44c3a36f601347e186604ca2ad112194",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f7b9514118f4856aee95bf561ae3681",
              "IPY_MODEL_91e0f9af57cb464182b0a2b5f4190a90",
              "IPY_MODEL_508d5eca2471467bbca61616f3c9243a"
            ]
          }
        },
        "44c3a36f601347e186604ca2ad112194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f7b9514118f4856aee95bf561ae3681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_122ca26b4f594b9eaa9ab4969e34cf4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f355cc6925248d3986dd1ab5fff86dd"
          }
        },
        "91e0f9af57cb464182b0a2b5f4190a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f16bab836034c3c87d92fe2f655d8b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fdd009ed4954f32ad2cdd7757ece062"
          }
        },
        "508d5eca2471467bbca61616f3c9243a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c9da3d637f44920b24bab20e3a2eb4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 10.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a144bc43d9c64c69ae944d960b26983c"
          }
        },
        "122ca26b4f594b9eaa9ab4969e34cf4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f355cc6925248d3986dd1ab5fff86dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f16bab836034c3c87d92fe2f655d8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fdd009ed4954f32ad2cdd7757ece062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c9da3d637f44920b24bab20e3a2eb4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a144bc43d9c64c69ae944d960b26983c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "245a877e7869403085f1acf7b43e7753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a30f70667f1b4256bdafc2669dab1b1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75eb829aa681438082b2c5e3f6687f64",
              "IPY_MODEL_ea6ab231224f4eb5a284bfc41ffca09e",
              "IPY_MODEL_620764dec19f4b2baae1c2581b7cb9c3"
            ]
          }
        },
        "a30f70667f1b4256bdafc2669dab1b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75eb829aa681438082b2c5e3f6687f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1602cc84c0d24fb290a7a8e67ee45d5f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c29993c1edd748bea6c851a3f92ba5a7"
          }
        },
        "ea6ab231224f4eb5a284bfc41ffca09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_346ccd559a6848e8848a7ad300006eb7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_872bb85635b94b84a5600e19d821757a"
          }
        },
        "620764dec19f4b2baae1c2581b7cb9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e530ad809b94a968571893a7b56b9ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:17&lt;00:00, 30.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39c6a17d223a4a729b9e7b15fe898aba"
          }
        },
        "1602cc84c0d24fb290a7a8e67ee45d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c29993c1edd748bea6c851a3f92ba5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "346ccd559a6848e8848a7ad300006eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "872bb85635b94b84a5600e19d821757a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e530ad809b94a968571893a7b56b9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39c6a17d223a4a729b9e7b15fe898aba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "586eb7a3932c4bcda9cbf561c0a617e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5713817b36ae40cfad328ce74ef4dd2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e433803b0d6048b7ae680d849ad32767",
              "IPY_MODEL_f94e0dc0db2b4bdfaecf2e0635c2b020",
              "IPY_MODEL_45f93659d07c4dab8dfe05e85f3c18e7"
            ]
          }
        },
        "5713817b36ae40cfad328ce74ef4dd2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e433803b0d6048b7ae680d849ad32767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad424ba0e359482b9340e801c5cfe1b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_671cf9e2411e4df092cba813b62bf0bd"
          }
        },
        "f94e0dc0db2b4bdfaecf2e0635c2b020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d59b006dd9d041ddaaf886edd1a53b4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_674730a0022a480d843e2c24210ea801"
          }
        },
        "45f93659d07c4dab8dfe05e85f3c18e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a9f6f120659454a94754f5f0441feeb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.53MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_542e3d4cb8974ffb9a1b293d2c40b127"
          }
        },
        "ad424ba0e359482b9340e801c5cfe1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "671cf9e2411e4df092cba813b62bf0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d59b006dd9d041ddaaf886edd1a53b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "674730a0022a480d843e2c24210ea801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a9f6f120659454a94754f5f0441feeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "542e3d4cb8974ffb9a1b293d2c40b127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7babd6bf1364953b60502d0e9a649c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d566f84234be4c25967183a058ae5b9b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5417aefebcb4778a9806ee8a0396161",
              "IPY_MODEL_89be33f5d8bb499ab4f94bcf7cdf3a93",
              "IPY_MODEL_125835ca085d4391ad1426fccfaeb76f"
            ]
          }
        },
        "d566f84234be4c25967183a058ae5b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5417aefebcb4778a9806ee8a0396161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3149406a26544d1db8b1e0edbe919ff2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58e7479c868d44b4bd0bb3f5e68f25ad"
          }
        },
        "89be33f5d8bb499ab4f94bcf7cdf3a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f45ddcc33760486da37a590ba0cdee72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f890d1076114e3d923dd5bf9ccacaab"
          }
        },
        "125835ca085d4391ad1426fccfaeb76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85154cd27faa44e1bff2bcc5b56b7a5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 974kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca82f3d969f64873bf50309962ae1975"
          }
        },
        "3149406a26544d1db8b1e0edbe919ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58e7479c868d44b4bd0bb3f5e68f25ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f45ddcc33760486da37a590ba0cdee72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f890d1076114e3d923dd5bf9ccacaab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85154cd27faa44e1bff2bcc5b56b7a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca82f3d969f64873bf50309962ae1975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashgupta-7/689_project/blob/main/winobias_attention_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7HGJObmD7OC",
        "outputId": "b7cf120e-3b94-43a1-e088-3f21e1c45645"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSYsl8YoHLya",
        "outputId": "ec70ecc9-9a80-4aa0-f0a9-505fd0a70101"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/cs689_project\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/cs689_project\n",
            "professions_data  results  winobias_data  winobias.py  winogender_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoLPKGBXHThH",
        "outputId": "8324a72e-9b94-47d4-9d64-c954159f4f53"
      },
      "source": [
        "!pip install transformers==3.0.2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 29.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.3)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEVbuTvTHeir"
      },
      "source": [
        "model_name = \"gpt2\"\n",
        "device = \"cuda\"\n",
        "out_dir = \".\"\n",
        "random_weights = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfmrCQFaIwEm"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "\n",
        "class Model():\n",
        "  def __init__(self,\n",
        "               device='cpu',\n",
        "               output_attentions=False,\n",
        "               random_weights=False,\n",
        "               gpt2_version='gpt2'):\n",
        "        super()\n",
        "        self.device = device\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(gpt2_version, output_attentions=output_attentions)\n",
        "        self.model.eval()\n",
        "        self.model.to(device)\n",
        "        if random_weights:\n",
        "            print('Randomizing weights')\n",
        "            self.model.init_weights()\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained(gpt2_version)\n",
        "\n",
        "        self.attention_layer = lambda layer: self.model.transformer.h[layer].attn\n",
        "        self.word_emb_layer = self.model.transformer.wte\n",
        "        self.neuron_layer = lambda layer: self.model.transformer.h[layer].mlp\n",
        "\n",
        "        self.num_layers = self.model.config.num_hidden_layers\n",
        "        self.num_neurons = self.model.config.hidden_size\n",
        "        self.num_heads = self.model.config.num_attention_heads\n",
        "\n",
        "  def get_probabilities_for_examples_multitoken(self, context, candidates):\n",
        "        \"\"\"\n",
        "        Return probability of multi-token candidates given context.\n",
        "        Prob of each candidate is normalized by number of tokens.\n",
        "        Args:\n",
        "            context: Tensor of token ids in context\n",
        "            candidates: list of list of token ids in each candidate\n",
        "        Returns: list containing probability for each candidate\n",
        "        \"\"\"\n",
        "        # TODO: Combine into single batch\n",
        "        mean_probs = []\n",
        "        context = context.tolist()\n",
        "        for candidate in candidates:\n",
        "            token_log_probs = []\n",
        "            combined = context + candidate\n",
        "            # Exclude last token position when predicting next token\n",
        "            batch = torch.tensor(combined[:-1]).unsqueeze(dim=0).to(self.device)\n",
        "            # Shape (batch_size, seq_len, vocab_size)\n",
        "            logits = self.model(batch)[0]\n",
        "            # Shape (seq_len, vocab_size)\n",
        "            log_probs = F.log_softmax(logits[-1, :, :], dim=-1)\n",
        "            context_end_pos = len(context) - 1\n",
        "            continuation_end_pos = context_end_pos + len(candidate)\n",
        "            # TODO: Vectorize this\n",
        "            # Up to but not including last token position\n",
        "            for i in range(context_end_pos, continuation_end_pos):\n",
        "                next_token_id = combined[i+1]\n",
        "                next_token_log_prob = log_probs[i][next_token_id].item()\n",
        "                token_log_probs.append(next_token_log_prob)\n",
        "            mean_token_log_prob = statistics.mean(token_log_probs)\n",
        "            mean_token_prob = math.exp(mean_token_log_prob)\n",
        "            mean_probs.append(mean_token_prob)\n",
        "        return mean_probs\n",
        "\n",
        "  def attention_intervention_experiment(self, intervention, effect):\n",
        "        \"\"\"\n",
        "        Run one full attention intervention experiment\n",
        "        measuring indirect or direct effect.\n",
        "        \"\"\"\n",
        "        # E.g. The doctor asked the nurse a question. He\n",
        "        x = intervention.base_strings_tok[0]\n",
        "        # E.g. The doctor asked the nurse a question. She\n",
        "        x_alt = intervention.base_strings_tok[1]\n",
        "\n",
        "        if effect == 'indirect':\n",
        "            input = x_alt  # Get attention for x_alt\n",
        "        elif effect == 'direct':\n",
        "            input = x  # Get attention for x\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid effect: {effect}\")\n",
        "        batch = input.clone().detach().unsqueeze(0).to(self.device)\n",
        "        attention_override = self.model(batch)[-1]\n",
        "\n",
        "        batch_size = 1\n",
        "        seq_len = len(x)\n",
        "        seq_len_alt = len(x_alt)\n",
        "        assert seq_len == seq_len_alt\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            candidate1_probs_head = torch.zeros((self.num_layers, self.num_heads))\n",
        "            candidate2_probs_head = torch.zeros((self.num_layers, self.num_heads))\n",
        "            candidate1_probs_layer = torch.zeros(self.num_layers)\n",
        "            candidate2_probs_layer = torch.zeros(self.num_layers)\n",
        "\n",
        "            if effect == 'indirect':\n",
        "                context = x\n",
        "            else:\n",
        "                context = x_alt\n",
        "\n",
        "            # Intervene at every layer and head by overlaying attention induced by x_alt\n",
        "            model_attn_override_data = [] # Save layer interventions for model-level intervention later\n",
        "            for layer in range(self.num_layers):\n",
        "                layer_attention_override = attention_override[layer]\n",
        "                attention_override_mask = torch.ones_like(layer_attention_override, dtype=torch.uint8)\n",
        "                layer_attn_override_data = [{\n",
        "                    'layer': layer,\n",
        "                    'attention_override': layer_attention_override,\n",
        "                    'attention_override_mask': attention_override_mask\n",
        "                }]\n",
        "                candidate1_probs_layer[layer], candidate2_probs_layer[layer] = self.attention_intervention(\n",
        "                    context=context,\n",
        "                    outputs=intervention.candidates_tok,\n",
        "                    attn_override_data = layer_attn_override_data)\n",
        "                model_attn_override_data.extend(layer_attn_override_data)\n",
        "                for head in range(self.num_heads):\n",
        "                    attention_override_mask = torch.zeros_like(layer_attention_override, dtype=torch.uint8)\n",
        "                    attention_override_mask[0][head] = 1 # Set mask to 1 for single head only\n",
        "                    head_attn_override_data = [{\n",
        "                        'layer': layer,\n",
        "                        'attention_override': layer_attention_override,\n",
        "                        'attention_override_mask': attention_override_mask\n",
        "                    }]\n",
        "                    candidate1_probs_head[layer][head], candidate2_probs_head[layer][head] = self.attention_intervention(\n",
        "                        context=context,\n",
        "                        outputs=intervention.candidates_tok,\n",
        "                        attn_override_data=head_attn_override_data)\n",
        "\n",
        "            # Intervene on entire model by overlaying attention induced by x_alt\n",
        "            candidate1_probs_model, candidate2_probs_model = self.attention_intervention(\n",
        "                context=context,\n",
        "                outputs=intervention.candidates_tok,\n",
        "                attn_override_data=model_attn_override_data)\n",
        "\n",
        "        return candidate1_probs_head, candidate2_probs_head, candidate1_probs_layer, candidate2_probs_layer,\\\n",
        "            candidate1_probs_model, candidate2_probs_model\n",
        "\n",
        "  def attention_intervention(self,\n",
        "                               context,\n",
        "                               outputs,\n",
        "                               attn_override_data):\n",
        "        \"\"\" Override attention values in specified layer\n",
        "        Args:\n",
        "            context: context text\n",
        "            outputs: candidate outputs\n",
        "            attn_override_data: list of dicts of form:\n",
        "                {\n",
        "                    'layer': <index of layer on which to intervene>,\n",
        "                    'attention_override': <values to override the computed attention weights.\n",
        "                           Shape is [batch_size, num_heads, seq_len, seq_len]>,\n",
        "                    'attention_override_mask': <indicates which attention weights to override.\n",
        "                                Shape is [batch_size, num_heads, seq_len, seq_len]>\n",
        "                }\n",
        "        \"\"\"\n",
        "\n",
        "        def intervention_hook(module, input, outputs, attn_override, attn_override_mask):\n",
        "            attention_override_module = (AttentionOverride)(module, attn_override, attn_override_mask)\n",
        "            return attention_override_module(*input)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            hooks = []\n",
        "            for d in attn_override_data:\n",
        "                attn_override = d['attention_override']\n",
        "                attn_override_mask = d['attention_override_mask']\n",
        "                layer = d['layer']\n",
        "                hooks.append(self.attention_layer(layer).register_forward_hook(\n",
        "                    partial(intervention_hook,\n",
        "                            attn_override=attn_override,\n",
        "                            attn_override_mask=attn_override_mask)))\n",
        "\n",
        "            new_probabilities = self.get_probabilities_for_examples_multitoken(\n",
        "                context,\n",
        "                outputs)\n",
        "\n",
        "            for hook in hooks:\n",
        "                hook.remove()\n",
        "\n",
        "            return new_probabilities"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUWgMY_MYFzx"
      },
      "source": [
        "class Intervention():\n",
        "       def __init__(self,\n",
        "                  tokenizer,\n",
        "                  base_string: str,\n",
        "                  substitutes: list,\n",
        "                  candidates: list,\n",
        "                  device='cpu'):\n",
        "          super()\n",
        "          self.device = device\n",
        "          self.enc = tokenizer\n",
        "\n",
        "          # First item should be neutral, others tainted\n",
        "          self.base_strings = [base_string.format(s)\n",
        "                              for s in substitutes]\n",
        "          # Tokenized bases\n",
        "          self.base_strings_tok = [\n",
        "              self.enc.encode(s,\n",
        "                              add_special_tokens=False)\n",
        "              for s in self.base_strings\n",
        "          ]\n",
        "          # print(self.base_strings, self.base_strings_tok)\n",
        "          self.base_strings_tok = torch.LongTensor(self.base_strings_tok)\\\n",
        "                                      .to(device)\n",
        "          self.position = base_string.split().index('{}')\n",
        "          self.candidates = []\n",
        "          for c in candidates:\n",
        "              # 'a ' added to input so that tokenizer understand that first word follows a space.\n",
        "              tokens = self.enc.tokenize(\n",
        "                  'a ' + c)[1:]\n",
        "              self.candidates.append(tokens)\n",
        "\n",
        "          self.candidates_tok = [self.enc.convert_tokens_to_ids(tokens)\n",
        "                                for tokens in self.candidates]\n",
        "\n",
        "def construct_interventions(base_sent, professions, tokenizer, DEVICE):\n",
        "    interventions = {}\n",
        "    unused = 0\n",
        "    for p in professions:\n",
        "      try:\n",
        "        interventions[p] = Intervention(tokenizer, base_sent, [p, \"man\", \"woman\"], [\"he\", \"she\"], device=DEVICE)\n",
        "      except:\n",
        "        unused += 1\n",
        "    print(\"Unused Professions\", unused)\n",
        "    return interventions"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "fabc56aa28f74782b2663569cbe6c603",
            "44c3a36f601347e186604ca2ad112194",
            "8f7b9514118f4856aee95bf561ae3681",
            "91e0f9af57cb464182b0a2b5f4190a90",
            "508d5eca2471467bbca61616f3c9243a",
            "122ca26b4f594b9eaa9ab4969e34cf4e",
            "4f355cc6925248d3986dd1ab5fff86dd",
            "9f16bab836034c3c87d92fe2f655d8b1",
            "7fdd009ed4954f32ad2cdd7757ece062",
            "0c9da3d637f44920b24bab20e3a2eb4a",
            "a144bc43d9c64c69ae944d960b26983c",
            "245a877e7869403085f1acf7b43e7753",
            "a30f70667f1b4256bdafc2669dab1b1b",
            "75eb829aa681438082b2c5e3f6687f64",
            "ea6ab231224f4eb5a284bfc41ffca09e",
            "620764dec19f4b2baae1c2581b7cb9c3",
            "1602cc84c0d24fb290a7a8e67ee45d5f",
            "c29993c1edd748bea6c851a3f92ba5a7",
            "346ccd559a6848e8848a7ad300006eb7",
            "872bb85635b94b84a5600e19d821757a",
            "9e530ad809b94a968571893a7b56b9ab",
            "39c6a17d223a4a729b9e7b15fe898aba",
            "586eb7a3932c4bcda9cbf561c0a617e1",
            "5713817b36ae40cfad328ce74ef4dd2d",
            "e433803b0d6048b7ae680d849ad32767",
            "f94e0dc0db2b4bdfaecf2e0635c2b020",
            "45f93659d07c4dab8dfe05e85f3c18e7",
            "ad424ba0e359482b9340e801c5cfe1b3",
            "671cf9e2411e4df092cba813b62bf0bd",
            "d59b006dd9d041ddaaf886edd1a53b4b",
            "674730a0022a480d843e2c24210ea801",
            "3a9f6f120659454a94754f5f0441feeb",
            "542e3d4cb8974ffb9a1b293d2c40b127",
            "d7babd6bf1364953b60502d0e9a649c7",
            "d566f84234be4c25967183a058ae5b9b",
            "b5417aefebcb4778a9806ee8a0396161",
            "89be33f5d8bb499ab4f94bcf7cdf3a93",
            "125835ca085d4391ad1426fccfaeb76f",
            "3149406a26544d1db8b1e0edbe919ff2",
            "58e7479c868d44b4bd0bb3f5e68f25ad",
            "f45ddcc33760486da37a590ba0cdee72",
            "5f890d1076114e3d923dd5bf9ccacaab",
            "85154cd27faa44e1bff2bcc5b56b7a5b",
            "ca82f3d969f64873bf50309962ae1975"
          ]
        },
        "id": "2wP_Xhv9IwSB",
        "outputId": "f6c77f4c-df8f-4dca-e813-28f1a0b4bf94"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "\n",
        "model = Model(output_attentions=True, gpt2_version=model_name, device=device, random_weights=random_weights)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fabc56aa28f74782b2663569cbe6c603",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "245a877e7869403085f1acf7b43e7753",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "586eb7a3932c4bcda9cbf561c0a617e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7babd6bf1364953b60502d0e9a649c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0KzjQZaZa9s",
        "outputId": "67083586-862a-4757-ebb8-85da3639a529"
      },
      "source": [
        "import os, re\n",
        "class WinobiasExample():\n",
        "\n",
        "    def __init__(self, base_string, female_pronoun, male_pronoun, female_occupation, male_occupation,\n",
        "                 female_occupation_continuation, male_occupation_continuation):\n",
        "        self.base_string = base_string\n",
        "        self.female_pronoun = female_pronoun\n",
        "        self.male_pronoun = male_pronoun\n",
        "        self.female_occupation = female_occupation\n",
        "        self.male_occupation = male_occupation\n",
        "        self.female_occupation_continuation = female_occupation_continuation\n",
        "        self.male_occupation_continuation = male_occupation_continuation\n",
        "\n",
        "    def to_intervention(self, tokenizer):\n",
        "        return Intervention(\n",
        "            tokenizer=tokenizer,\n",
        "            base_string=self.base_string,\n",
        "            substitutes=[self.female_pronoun, self.male_pronoun],\n",
        "            candidates=[self.female_occupation_continuation, self.male_occupation_continuation]\n",
        "        )\n",
        "\n",
        "    def __str__(self):\n",
        "        return inspect.cleandoc(f\"\"\"\n",
        "            base_string: {self.base_string}\n",
        "            female_pronoun: {self.female_pronoun}\n",
        "            male_pronoun: {self.male_pronoun}\n",
        "            female_occupation: {self.female_occupation}\n",
        "            male_occupation: {self.male_occupation}\n",
        "            female_occupation_continuation: {self.female_occupation_continuation}\n",
        "            male_occupation_continuation: {self.male_occupation_continuation}\n",
        "        \"\"\")\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self).replace('\\n', ' ')\n",
        "\n",
        "def _parse_row(row, occupations):\n",
        "    _, sentence = row.strip().split(' ', 1)\n",
        "    occupation = None\n",
        "    for occ in occupations:\n",
        "        if f'[the {occ.lower()}]' in sentence.lower():\n",
        "            assert occupation is None\n",
        "            occupation = occ.lower()\n",
        "    assert occupation is not None\n",
        "\n",
        "    pronoun_groups = [ # First element is female, second is male\n",
        "        ('she', 'he'), # nominative\n",
        "        ('her', 'his') # possessive\n",
        "    ]\n",
        "\n",
        "    num_matches = 0\n",
        "    substitutes = None\n",
        "    for pronouns in pronoun_groups:\n",
        "        pattern = '|'.join(r'\\[' + p + r'\\]' for p in pronouns) # matches '[he]', '[she]', etc.\n",
        "        pronoun_matches = re.findall(pattern, sentence)\n",
        "        assert len(pronoun_matches) <= 1\n",
        "        if pronoun_matches:\n",
        "            num_matches += 1\n",
        "            pronoun_match = pronoun_matches[0]\n",
        "            context, continuation = sentence.split(pronoun_match)\n",
        "            context = context.replace('[', '').replace(']', '')\n",
        "            context = context.strip()\n",
        "            assert '[' not in continuation\n",
        "            continuation = continuation.strip()\n",
        "            substitutes = pronouns\n",
        "    assert num_matches == 1\n",
        "    base_string = context + ' {}'\n",
        "\n",
        "    return base_string, substitutes, continuation, occupation\n",
        "\n",
        "def load_examples(path, verbose=False):\n",
        "    with open(os.path.join(path, 'female_occupations.txt')) as f:\n",
        "        female_occupations = [row.lower().strip() for row in f]\n",
        "    with open(os.path.join(path, 'male_occupations.txt')) as f:\n",
        "        male_occupations = [row.lower().strip() for row in f]\n",
        "    occupations = female_occupations + male_occupations\n",
        "\n",
        "    fname = f'pro_stereotyped_type1.txt.dev'\n",
        "\n",
        "    with open(os.path.join(path, fname)) as f:\n",
        "        examples = []\n",
        "        row_pair = []\n",
        "        skip_count = 0\n",
        "        for row in f:\n",
        "            row_pair.append(row)\n",
        "            if len(row_pair) == 2:\n",
        "                skip = False\n",
        "                if row_pair[0].count('[') != 2 or row_pair[1].count('[') != 2: # Multiple pronouns\n",
        "                    skip = True\n",
        "                elif '[him]' in row_pair[0] + row_pair[1]: # Objective pronoun, almost always at end of sentence\n",
        "                    skip = True\n",
        "                else:\n",
        "                    base_string1, substitutes1, continuation1, occupation1 = _parse_row(row_pair[0], occupations)\n",
        "                    base_string2, substitutes2, continuation2, occupation2 = _parse_row(row_pair[1], occupations)\n",
        "                    if base_string1 != base_string2 or substitutes1 != substitutes2:\n",
        "                        skip = True\n",
        "                if skip:\n",
        "                    if verbose:\n",
        "                        print('Skipping: ', row_pair)\n",
        "                    skip_count += 1\n",
        "                    row_pair = []\n",
        "                    continue\n",
        "                base_string = base_string1\n",
        "                assert substitutes1 == substitutes2\n",
        "                female_pronoun, male_pronoun = substitutes1\n",
        "                assert len(continuation1) > 0 and len(continuation2) > 0 and continuation1 != continuation2\n",
        "                assert len(occupation1) > 0 and len(occupation2) > 0 and occupation1 != occupation2\n",
        "                if occupation1 in female_occupations:\n",
        "                    female_occupation = occupation1\n",
        "                    female_occupation_continuation = continuation1\n",
        "                    male_occupation = occupation2\n",
        "                    male_occupation_continuation = continuation2\n",
        "                    assert occupation2 in male_occupations\n",
        "                else:\n",
        "                    male_occupation = occupation1\n",
        "                    male_occupation_continuation = continuation1\n",
        "                    female_occupation = occupation2\n",
        "                    female_occupation_continuation = continuation2\n",
        "                    assert occupation1 in male_occupations\n",
        "                    assert occupation2 in female_occupations\n",
        "                examples.append(WinobiasExample(base_string, female_pronoun, male_pronoun, female_occupation, male_occupation,\n",
        "                 female_occupation_continuation, male_occupation_continuation))\n",
        "                row_pair = []\n",
        "        assert row_pair == []\n",
        "    print(f'Loaded {len(examples)} pairs. Skipped {skip_count} pairs.')\n",
        "    return examples\n",
        "\n",
        "import torch\n",
        "examples = load_examples('winobias_data/')\n",
        "json_data = {'model_version': model_name,\n",
        "            'do_filter': False,\n",
        "            'split': 'dev',\n",
        "            'num_examples_loaded': len(examples)}\n",
        "json_data['num_examples_analyzed'] = len(examples)\n",
        "interventions = [ex.to_intervention(tokenizer) for ex in examples]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 160 pairs. Skipped 38 pairs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89ziRsbaJFId",
        "outputId": "10f9fa5d-aaac-4d23-c71f-be6f150d941b"
      },
      "source": [
        "def perform_intervention(intervention, model, effect_types=('indirect', 'direct')):\n",
        "    \"\"\"Perform intervention and return results for specified effects\"\"\"\n",
        "    x = intervention.base_strings_tok[0]  # E.g. The doctor asked the nurse a question. She\n",
        "    x_alt = intervention.base_strings_tok[1]  # E.g. The doctor asked the nurse a question. He\n",
        "\n",
        "    with torch.no_grad():\n",
        "        candidate1_base_prob, candidate2_base_prob = model.get_probabilities_for_examples_multitoken(\n",
        "            x,\n",
        "            intervention.candidates_tok)\n",
        "        candidate1_alt_prob, candidate2_alt_prob = model.get_probabilities_for_examples_multitoken(\n",
        "            x_alt,\n",
        "            intervention.candidates_tok)\n",
        "\n",
        "    candidate1 = ' '.join(intervention.candidates[0]).replace('Ġ', '')\n",
        "    candidate2 = ' '.join(intervention.candidates[1]).replace('Ġ', '')\n",
        "\n",
        "    odds_base = candidate2_base_prob / candidate1_base_prob\n",
        "    odds_alt = candidate2_alt_prob / candidate1_alt_prob\n",
        "    total_effect = (odds_alt - odds_base) / odds_base\n",
        "\n",
        "    results = {\n",
        "        'base_string1': intervention.base_strings[0],\n",
        "        'base_string2': intervention.base_strings[1],\n",
        "        'candidate1': candidate1,\n",
        "        'candidate2': candidate2,\n",
        "        'candidate1_base_prob': candidate1_base_prob,\n",
        "        'candidate2_base_prob': candidate2_base_prob,\n",
        "        'odds_base': odds_base,\n",
        "        'candidate1_alt_prob': candidate1_alt_prob,\n",
        "        'candidate2_alt_prob': candidate2_alt_prob,\n",
        "        'odds_alt': odds_alt,\n",
        "        'total_effect': total_effect,\n",
        "    }\n",
        "\n",
        "    for effect_type in effect_types:\n",
        "        candidate1_probs_head, candidate2_probs_head, candidate1_probs_layer, candidate2_probs_layer,\\\n",
        "            candidate1_probs_model, candidate2_probs_model = model.attention_intervention_experiment(\n",
        "            intervention, effect_type)\n",
        "        odds_intervention_head = candidate2_probs_head / candidate1_probs_head\n",
        "        odds_intervention_layer = candidate2_probs_layer / candidate1_probs_layer\n",
        "        odds_intervention_model = candidate2_probs_model / candidate1_probs_model\n",
        "        effect_head = (odds_intervention_head - odds_base) / odds_base\n",
        "        effect_layer = (odds_intervention_layer - odds_base) / odds_base\n",
        "        effect_model = (odds_intervention_model - odds_base) / odds_base\n",
        "\n",
        "        results[effect_type + \"_odds_head\"] = odds_intervention_head.tolist()\n",
        "        results[effect_type + \"_effect_head\"] = effect_head.tolist()\n",
        "        results[effect_type + \"_effect_layer\"] = effect_layer.tolist()\n",
        "        results[effect_type + \"_effect_model\"] = effect_model\n",
        "\n",
        "    return results\n",
        "\n",
        "def perform_interventions(interventions, model, effect_types=('indirect', 'direct')):\n",
        "    \"\"\"Perform multiple interventions\"\"\"\n",
        "    results_list = []\n",
        "    for intervention in tqdm(interventions):\n",
        "        results = perform_intervention(intervention, model, effect_types)\n",
        "        results_list.append(results)\n",
        "    return results_list\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import os\n",
        "from copy import deepcopy\n",
        "import statistics\n",
        "import math\n",
        "import torch.nn as nn\n",
        "\n",
        "class AttentionOverride(nn.Module):\n",
        "    \"\"\"A copy of `modeling_gpt2.Attention` class, but with overridden attention values\"\"\"\n",
        "\n",
        "    def __init__(self, attention, attn_override, attn_override_mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            attention: instance of modeling_gpt2.Attention from which variables will be\n",
        "                       copied.\n",
        "            attn_override: values to override the computed attention weights.\n",
        "                           Shape is [num_heads, seq_len, seq_len]\n",
        "            attn_override_mask: indicates which attention weights to override.\n",
        "                                Shape is [num_heads, seq_len, seq_len]\n",
        "        \"\"\"\n",
        "        super(AttentionOverride, self).__init__()\n",
        "        # Copy values from attention\n",
        "        self.output_attentions = True #attention.output_attentions\n",
        "        self.register_buffer(\"bias\", attention._buffers[\"bias\"])\n",
        "        self.n_head = attention.n_head\n",
        "        self.split_size = attention.split_size\n",
        "        self.scale = attention.scale\n",
        "        self.c_attn = attention.c_attn\n",
        "        self.c_proj = attention.c_proj\n",
        "        self.attn_dropout = attention.attn_dropout\n",
        "        self.resid_dropout = attention.resid_dropout\n",
        "        # Set attention override values\n",
        "        self.attn_override = attn_override\n",
        "        self.attn_override_mask = attn_override_mask\n",
        "\n",
        "    def _attn(self, q, k, v, attention_mask=None, head_mask=None):\n",
        "        w = torch.matmul(q, k)\n",
        "        if self.scale:\n",
        "            w = w / math.sqrt(v.size(-1))\n",
        "        nd, ns = w.size(-2), w.size(-1)\n",
        "        b = self.bias[:, :, ns - nd : ns, :ns]\n",
        "        w = w * b - 1e4 * (1 - b)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask\n",
        "            w = w + attention_mask\n",
        "\n",
        "        w = nn.Softmax(dim=-1)(w)\n",
        "        w = self.attn_dropout(w)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            w = w * head_mask\n",
        "\n",
        "        # attn_override and attn_override_mask are of shape\n",
        "        # (batch_size, num_heads, override_seq_len, override_seq_len)\n",
        "        # where override_seq_len is the length of subsequence for which attention is\n",
        "        # being overridden.\n",
        "        override_seq_len = self.attn_override_mask.shape[-1]\n",
        "        w[:, :, :override_seq_len, :override_seq_len] = torch.where(\n",
        "            self.attn_override_mask,\n",
        "            self.attn_override,\n",
        "            w[:, :, :override_seq_len, :override_seq_len],\n",
        "        )\n",
        "\n",
        "        outputs = [torch.matmul(w, v)]\n",
        "        if self.output_attentions:\n",
        "            outputs.append(w)\n",
        "        return outputs\n",
        "\n",
        "    def merge_heads(self, x):\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
        "        return x.view(*new_x_shape)  # in Tensorflow implem: fct merge_states\n",
        "\n",
        "    def split_heads(self, x, k=False):\n",
        "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
        "        x = x.view(*new_x_shape)  # in Tensorflow implem: fct split_states\n",
        "        if k:\n",
        "            return x.permute(0, 2, 3, 1)  # (batch, head, head_features, seq_length)\n",
        "        else:\n",
        "            return x.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
        "\n",
        "    def forward(self, x, layer_past=None, attention_mask=None, head_mask=None):\n",
        "        x = self.c_attn(x)\n",
        "        query, key, value = x.split(self.split_size, dim=2)\n",
        "        query = self.split_heads(query)\n",
        "        key = self.split_heads(key, k=True)\n",
        "        value = self.split_heads(value)\n",
        "        if layer_past is not None:\n",
        "            past_key, past_value = (\n",
        "                layer_past[0].transpose(-2, -1),\n",
        "                layer_past[1],\n",
        "            )  # transpose back cf below\n",
        "            key = torch.cat((past_key, key), dim=-1)\n",
        "            value = torch.cat((past_value, value), dim=-2)\n",
        "        present = torch.stack(\n",
        "            (key.transpose(-2, -1), value)\n",
        "        )  # transpose to have same shapes for stacking\n",
        "\n",
        "        attn_outputs = self._attn(query, key, value, attention_mask, head_mask)\n",
        "        a = attn_outputs[0]\n",
        "\n",
        "        a = self.merge_heads(a)\n",
        "        a = self.c_proj(a)\n",
        "        a = self.resid_dropout(a)\n",
        "\n",
        "        outputs = [a, present] + attn_outputs[1:]\n",
        "        return outputs  # a, present, (attentions)\n",
        "\n",
        "results = perform_interventions(interventions, model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/160 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)\n",
            "100%|██████████| 160/160 [33:04<00:00, 12.40s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "OKY_qCJ8sADa",
        "outputId": "490b50c6-5a3e-41ff-abba-4db5bf05d89f"
      },
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "json_data['mean_total_effect'] = DataFrame(results).total_effect.mean()\n",
        "json_data['mean_model_indirect_effect'] = DataFrame(results).indirect_effect_model.mean()\n",
        "json_data['mean_model_direct_effect'] = DataFrame(results).direct_effect_model.mean()\n",
        "filter_name = 'unfiltered'\n",
        "if random_weights:\n",
        "    gpt2_version += '_random'\n",
        "fname = f\"winobias_data/attention_intervention_{model_name}_{filter_name}_{split}.json\"\n",
        "json_data['results'] = results\n",
        "with open(fname, 'w') as f:\n",
        "    json.dump(json_data, f)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7b0904869a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_total_effect'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_effect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_model_indirect_effect'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindirect_effect_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_model_direct_effect'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirect_effect_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilter_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'unfiltered'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrandom_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataFrame' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUWt-EW0bfEL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}